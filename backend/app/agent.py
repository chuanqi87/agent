#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from typing import List, Dict, Any, Optional
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnableLambda
from langchain_core.tools import tool
from langchain.memory import ConversationBufferWindowMemory
from langchain.agents import AgentExecutor, create_openai_tools_agent
from .config import get_settings
from .tools import TOOLS

class ChatAgent:
    """åŸºäºLangChainå’Œlangserveçš„èŠå¤©ä»£ç†"""
    
    def __init__(self):
        """åˆå§‹åŒ–èŠå¤©ä»£ç†"""
        self.settings = get_settings()
        self.model_config = self.settings.get_active_model_config()
        self.setup_llm()
        self.setup_tools()
        self.setup_agent()
        self.setup_memory()
        
    def setup_llm(self):
        """è®¾ç½®LangChain LLM"""
        if not self.model_config["api_key"]:
            raise ValueError(f"è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®{self.model_config['provider'].upper()}_API_KEY")
        
        provider = self.model_config["provider"]
        model_name = self.model_config["model"]
        base_url = self.model_config["base_url"]
        
        # å¯¹äºGeminiï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
        if provider == "gemini":
            if "generativelanguage.googleapis.com" in base_url:
                base_url = f"{base_url}/openai"
        
        self.llm = ChatOpenAI(
            openai_api_key=self.model_config["api_key"],
            openai_api_base=base_url,
            model_name=model_name,
            temperature=0.7,
            max_tokens=2000,
            streaming=True  # æ”¯æŒæµå¼å“åº”
        )
        
        print(f"âœ… LangChain LLM åˆå§‹åŒ–æˆåŠŸ - {provider.upper()} {model_name}")
    
    def setup_tools(self):
        """è®¾ç½®å·¥å…·"""
        self.tools = TOOLS
        print(f"ğŸ”§ å·¥å…·åˆå§‹åŒ–å®Œæˆ - {len(self.tools)} ä¸ªå·¥å…·")
    
    def setup_agent(self):
        """è®¾ç½®Agent"""
        # åˆ›å»ºç³»ç»Ÿæç¤º
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ã€‚è¯·éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š

1. ç”¨ä¸­æ–‡å›ç­”é—®é¢˜
2. ä¿æŒå‹å¥½å’Œä¸“ä¸šçš„è¯­è°ƒ
3. å¦‚æœä¸ç¡®å®šç­”æ¡ˆï¼Œè¯·è¯šå®è¯´æ˜
4. åˆç†ä½¿ç”¨å¯ç”¨çš„å·¥å…·æ¥å¸®åŠ©ç”¨æˆ·
5. å±•ç°æ·±åº¦æ€è€ƒå’Œæ¨ç†èƒ½åŠ›

è¯·æ ¹æ®ç”¨æˆ·çš„éœ€æ±‚é€‰æ‹©åˆé€‚çš„å·¥å…·ã€‚"""
        
        # åˆ›å»ºæç¤ºæ¨¡æ¿
        prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            MessagesPlaceholder(variable_name="chat_history"),
            ("human", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ])
        
        # åˆ›å»ºOpenAIå·¥å…·ä»£ç†
        self.agent = create_openai_tools_agent(
            llm=self.llm,
            tools=self.tools,
            prompt=prompt
        )
        
        # åˆ›å»ºä»£ç†æ‰§è¡Œå™¨
        self.agent_executor = AgentExecutor(
            agent=self.agent,
            tools=self.tools,
            verbose=True,
            handle_parsing_errors=True,
            max_iterations=3
        )
        
        print("ğŸ¤– Agent åˆå§‹åŒ–å®Œæˆ")
    
    def setup_memory(self):
        """è®¾ç½®è®°å¿†"""
        self.memory = ConversationBufferWindowMemory(
            k=10,  # ä¿ç•™æœ€è¿‘10è½®å¯¹è¯
            return_messages=True,
            memory_key="chat_history"
        )
        print("ğŸ§  è®°å¿†ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    def get_chain(self):
        """è·å–å¯ç”¨äºlangserveçš„é“¾"""
        def format_input(input_data):
            """æ ¼å¼åŒ–è¾“å…¥"""
            if isinstance(input_data, dict):
                user_input = input_data.get("input", "")
            else:
                user_input = str(input_data)
            
            # è·å–èŠå¤©å†å²
            chat_history = self.memory.chat_memory.messages
            
            return {
                "input": user_input,
                "chat_history": chat_history,
                "agent_scratchpad": []
            }
        
        def save_to_memory(result):
            """ä¿å­˜åˆ°è®°å¿†"""
            input_msg = result.get("input", "")
            output_msg = result.get("output", "")
            
            if input_msg and output_msg:
                self.memory.chat_memory.add_user_message(input_msg)
                self.memory.chat_memory.add_ai_message(output_msg)
            
            return result
        
        # åˆ›å»ºé“¾
        chain = (
            RunnableLambda(format_input) |
            self.agent_executor |
            RunnableLambda(save_to_memory)
        )
        
        return chain
    
    def get_model_info(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        return {
            "provider": self.model_config["provider"],
            "model": self.model_config["model"],
            "base_url": self.model_config["base_url"],
            "tools_count": len(self.tools),
            "tools": [tool.name for tool in self.tools]
        } 